---
title: "Demi journée Data Science"
author: "Lounas Chikhi"
date: "2025-2026"
---
  
### Chargement des librairies nécessaires

```{r,echo=FALSE,,message=FALSE}
library(readr)
library(dplyr)
library(ggplot2)
library(class)
library(caret)
library(pROC)


```


###  1. Préparation des données et sélection des features


```{r}

apprentissage <- read_csv("Data/farms_train.csv")
head(apprentissage)

y <- apprentissage$DIFF

# Sélection seulement des features pertinentes

X <- apprentissage %>% select(R2, R7, R8, R17, R22, R32)  # !!!!!!!!!!!!! a voir 


```


###   2. Partitionnement et préparation

```{r}



set.seed(42)
train <- createDataPartition(y, p = 0.8, list = FALSE) # poiur faire le partitionnement des données en apprentisage et validation 

X_train <- X[train, ]
y_train <- y[train]

X_val <- X[-train, ]
y_val <- y[-train]



```



###   3. Normalisation des données

```{r}

preProcValues <- preProcess(X_train, method = c("center", "scale"))
X_train_scaled <- predict(preProcValues, X_train)
X_val_scaled   <- predict(preProcValues, X_val)
```


###   4. Premier test avec k=15

```{r}

k <- 15
knn_pred <- knn(
  train = X_train_scaled,  # toutes les lignes du jeu d'apprentissage
  test  = X_val_scaled,    # chaque individu du jeu de validation
  cl    = y_train,         # classes correspondantes des individus d'apprentissage
  k     = k
)
```


###   5. Évaluation des performances

```{r}
confusionMatrix(knn_pred, as.factor(y_val))

```



###   6. Optimisation du paramètre k


```{r}


# Tester plusieurs k
k_values <- 1:20
results <- data.frame(k = integer(), Accuracy = numeric())

for(k in k_values){
  knn_pred <- knn(train = X_train_scaled,
                  test  = X_val_scaled,
                  cl    = y_train,
                  k     = k)
  
  acc <- sum(knn_pred == y_val) / length(y_val)
  results <- rbind(results, data.frame(k = k, Accuracy = acc))
}

best_k <- results$k[which.max(results$Accuracy)]
cat("Le meilleur k est :", best_k, "avec une accuracy de :", max(results$Accuracy), "\n")
# KNN avec prob=TRUE pour extraire les probabilités
knn_val_pred <- knn(
  train = X_train_scaled,
  test  = X_val_scaled,
  cl    = y_train,
  k     = best_k,
  prob  = TRUE
)

# Extraire probabilités de la classe positive
probabilities <- attr(knn_val_pred, "prob")
probabilities <- ifelse(knn_val_pred == 1, probabilities, 1 - probabilities)

# Courbe ROC
roc_curve <- roc(y_val, probabilities)
plot(roc_curve, main="Courbe ROC - KNN", col="blue", lwd=2)

# AUC
auc_value <- auc(roc_curve)
cat("AUC :", auc_value, "\n")


```



###   7. Sélection du meilleur k et modèle final

```{r}

ggplot(results, aes(x = k, y = Accuracy)) +
  geom_line(color = "blue") +
  geom_point(color = "red") +
  labs(title = "Accuracy vs k", x = "k", y = "Accuracy") +
  theme_minimal()

# Choisir le meilleur k
best_k <- results$k[which.max(results$Accuracy)]
cat("Le meilleur k est :", best_k, "avec une accuracy de :", max(results$Accuracy), "\n")

# Appliquer KNN final avec le meilleur k
knn_pred_final <- knn(train = X_train_scaled,
                      test  = X_val_scaled,
                      cl    = y_train,
                      k     = best_k)


```



###   8. Prédiction sur le Dataset test


```{r}
test <- read_csv("Data/farms_test.csv")
head(test)

X_test <- test %>% select(R2, R7, R8, R17, R22, R32)

X_test_scaled <- predict(preProcValues, X_test)
knn_test_pred <- knn(
  train = X_train_scaled,
  test  = X_test_scaled,
  cl    = y_train,
  k     = best_k
)

submission <- data.frame(
  ID = 1:nrow(test),
  DIFF = knn_test_pred
)

# Vérifier le résultat
head(submission)

write_csv(submission, "Data/soumission_knn.csv")

```





