---
title: "ACP + KNN"
author: "Lounas Chikhi"
date: "2025-09-17"
output: html_document
---

## KNN + ACP


### 1. Chargement des librairies nécessaires

```{r,echo=FALSE,,message=FALSE}
library(readr)
library(dplyr)
library(ggplot2)
library(class)
library(caret)
library(pROC)


```



### 2. Appliquer L'ACP 
```{r}

apprentissage <- read_csv("Data/farms_train.csv")

# Sélection des features
X_numeric <- apprentissage %>% select(R2, R7, R8, R17, R22, R32)
X_scaled <- scale(X_numeric)
y <- apprentissage$DIFF

# ACP sur données normalisées
pca_result <- prcomp(X_scaled, center = FALSE, scale. = FALSE)  # Déjà normalisé

```



### 3. Choix du nombre de CPs
```{r}

# Calcul de la variance expliquée
variance_explained <- pca_result$sdev^2 / sum(pca_result$sdev^2)
variance_cumulative <- cumsum(variance_explained) * 100

# Variance expliquée par composante
barplot(variance_explained * 100, 
        names.arg = paste0("CP", 1:6),
        main = "Variance expliquée par chaque composante",
        ylab = "Variance (%)", 
        col = "steelblue")


# Extraire les 4 premières composantes (cohérent avec votre choix)
X_pca <- data.frame(pca_result$x[, 1:4])

# Variance cumulée
plot(cumsum(variance_explained) * 100, type = "b", 
     main = "Variance cumulée", 
     xlab = "Nombre de composantes", 
     ylab = "Variance cumulée (%)")
abline(h = 80, col = "red", lty = 2)
# Ajouter ligne pour 4 CP
abline(v = 4, col = "blue", lty = 2)
text(4, 50, paste0("4 CP: ", round(sum(variance_explained[1:4])*100, 1), "%"), 
     pos = 4, col = "blue")

```
### 4. Modélisation du KNN 
```{r}
# Split apprentissage/validation
set.seed(42)
train_index <- createDataPartition(y, p = 0.8, list = FALSE)
X_train_pca <- X_pca[train_index, ]
y_train <- y[train_index]
X_val_pca <- X_pca[-train_index, ]
y_val <- y[-train_index]

# Optimisation k avec 4 composantes
k_values <- 1:50
results <- data.frame(k = integer(), Accuracy = numeric())

for(k in k_values){
  knn_pred <- knn(train = X_train_pca,
                  test  = X_val_pca,
                  cl    = y_train,
                  k     = k)  # ← RETIRÉ prob=TRUE de la boucle
  
  acc <- sum(knn_pred == y_val) / length(y_val)
  results <- rbind(results, data.frame(k = k, Accuracy = acc))
}

# Trouver le meilleur k
best_k <- results$k[which.max(results$Accuracy)]
cat("Meilleur k:", best_k, "- Accuracy:", round(max(results$Accuracy), 3), "\n")
```

### 5. Métriques de performances 
```{r}
# KNN FINAL avec le meilleur k et prob=TRUE pour ROC
knn_final <- knn(train = X_train_pca,
                 test  = X_val_pca,
                 cl    = y_train,
                 k     = best_k,
                 prob  = TRUE)  # ← ICI on récupère les probabilities

# Extraction des probabilités pour le meilleur k
probabilities <- attr(knn_final, "prob")
probabilities <- ifelse(knn_final == 1, probabilities, 1 - probabilities)

# Courbe ROC avec le BON k
roc_curve <- roc(y_val, probabilities, quiet = TRUE)
plot(roc_curve, 
     main = paste0("Courbe ROC - KNN + ACP (k=", best_k, ")"), 
     col = "blue", lwd = 2,
     print.auc = TRUE)

# AUC
auc_value <- auc(roc_curve)
cat("AUC :", round(auc_value, 3), "\n")

# Graphique Accuracy vs k
ggplot(results, aes(x = k, y = Accuracy)) +
  geom_line(color = "blue") +
  geom_point(color = "red") +
  geom_vline(xintercept = best_k, color = "red", linetype = "dashed") +
  geom_text(aes(x = best_k + 3, y = max(Accuracy) - 0.01, 
                label = paste0("k=", best_k)), color = "red") +
  labs(title = "Accuracy vs k (ACP 4 composantes)", 
       subtitle = paste0("Variance expliquée: ", round(sum(variance_explained[1:4])*100, 1), "%"),
       x = "k", y = "Accuracy") +
  theme_minimal()

# Résumé final
cat("\n=== RÉSULTATS FINAUX ===\n")
cat("Composantes utilisées: 4 CP (", round(sum(variance_explained[1:4])*100, 1), "% variance)\n")
cat("Meilleur k:", best_k, "\n")
cat("Accuracy:", round(max(results$Accuracy), 3), "\n")
cat("AUC:", round(auc_value, 3), "\n")

# Matrice de confusion
confusion_matrix <- table(Predicted = knn_final, Actual = y_val)
print("Matrice de confusion:")
print(confusion_matrix)
```




###   6. Prédiction sur le Dataset test

```{r}


test <- read_csv("Data/farms_test.csv")

# Sélectionner les features
X_test <- test %>% select(R2, R7, R8, R17, R22, R32)



# Normalisation avec les mêmes paramètres que l'entraînement
train_means <- attr(X_scaled, "scaled:center")
train_scales <- attr(X_scaled, "scaled:scale")

X_test_scaled <- scale(X_test, center = train_means, scale = train_scales)


# Projection des données test dans l'espace des CP
X_test_pca <- predict(pca_result, X_test_scaled)
X_test_pca_4d <- data.frame(X_test_pca[, 1:4])


# Prédiction KNN avec le modèle optimisé
knn_test_pred <- knn(
  train = X_train_pca,     # ← 4 composantes principales (train)
  test  = X_test_pca_4d,   # ← 4 composantes principales (test)
  cl    = y_train,         # ← Classes d'entraînement
  k     = best_k           # ← k optimal trouvé précédemment
)

submission <- data.frame(
  ID = 1:nrow(test),
  DIFF = as.numeric(as.character(knn_test_pred))
)

# Sauvegarder
write_csv(submission, "Data/soumission_knn_acp.csv")
cat("Fichier généré avec succès !\n")
```